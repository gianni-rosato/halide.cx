<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <base target="_self" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="alternate" type="application/atom+xml" title="Atom Feed" href="https://halide.cx/atom.xml">
    <link href="https://halide.cx/blog.css" rel="stylesheet" />
    <link href="https://halide.cx/main.css" rel="stylesheet" />
    <link href="https://halide.cx/metrics_table.css" rel="stylesheet" />
    <link href="https://halide.cx/mobile_menu.css" rel="stylesheet" />
    <link href="https://halide.cx/switcher.css" rel="stylesheet" />
    <link href="https://halide.cx/favicon.webp" rel="icon">
    <script
      defer
      src="https://cloud.umami.is/script.js"
      data-website-id="b3cce724-5063-4b5a-99d5-77f7d35b07d1"
    ></script>
    <title>
      Introducing fcvvdp | Halide Compression
    </title>
    <meta
      name="description"
      content="A faster implementation of CVVDP, a perceptual video and image fidelity metric."
    >
    <meta
      property="og:type"
      content="article"
    >
  </head>

  <body>
    <header class="site-header">
      <div class="container header-content">
        <div class="logo-nav-group">
          <a href="https://halide.cx/" class="logo">
            <img
              src="/img/halide_logo.svg"
              alt="Halide logo"
              class="logo-icon"
            >
          </a>
          <nav class="main-nav">
            <a href="https://halide.cx/about/">About</a>
            <a href="https://halide.cx/iris/">Iris</a>
            <a href="https://halide.cx/blog/">Blog</a>
          </nav>
        </div>

        <div class="flex items-center">
          <button class="mobile-menu-button" aria-label="Open menu">
            <svg
              xmlns="http://www.w3.org/2000/svg"
              fill="none"
              viewBox="0 0 24 24"
              stroke-width="1.5"
              stroke="currentColor"
            >
              <path
                stroke-linecap="round"
                stroke-linejoin="round"
                d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"
              />
            </svg>
          </button>
        </div>
      </div>
    </header>

    <main>
      <div class="container">
        
<article class="blog-post">
  <header class="blog-post-header">
    <div class="blog-post-meta">
      <time>December 28, 2025</time> â€¢
      <span class="author">The Halide Team</span>
    </div>
    <h1 class="blog-post-title">
      Introducing fcvvdp
    </h1>
  </header>
  <div class="blog-post-content">
    <p class="lead">
      A faster implementation of CVVDP, a perceptual video and image fidelity metric.
    </p>
    <div class="image-container">
  <picture>
    <img
      src="https://halide.cx/img/slate.avif"
      width="1536"
      height="864"
      alt="Slate"
    />
  </picture>
</div>
<h2 id="why">Why?</h2>
<p>The aphorism "all models are wrong, but some are useful" is commonly attributed to George E. P. Box, a British statistician. The concept is especially relevant in multimedia compression where we have lots of models to choose from for evaluating lossy image and video compression.</p>
<p>Lots of metrics exist and are easily accessible; we are intimately familiar with a wide breadth of metrics and their various pros and cons for benchmarking image compression algorithms, but there will always be blind spots regardless of how many we test. When we found ColorVideoVDP (CVVDP), we discovered it was able to catch some edge cases that other powerful perceptual metrics (like SSIMULACRA2) weren't able to; despite the fact that it has its own edge cases, it immediately became interesting to us because of this.</p>
<p>The only issue we faced was that the <a href="https://github.com/gfxdisp/colorvideovdp">reference Python implementation</a> was not fast enough for our use case, increasing our Iris benchmark script's runtime dramatically. This wasn't an acceptable trade-off for our productivity, so we decided to build <a href="https://github.com/halidecx/fcvvdp">fcvvdp</a> as an open-source C implementation of CVVDP for the benefit of everyone who may have faced the same issues we did.</p>
<h2 id="metrics">Metrics</h2>
<p>The strongest full-reference perceptual fidelity metrics we have access to are SSIMULACRA2, Butteraugli, and (to some degree) MS-SSIM. PSNR-HVS provides some level of perceptual utility as well. SSIM and eSSIM are occasionally useful for investigating a certain class of finer artifacts; the same can be said about PSNR to some degree. VMAF isn't particularly useful for images in our experience. We don't outright shun or ignore any metrics, but our preference is to build technology that is valuable for the end-user experience (so, the human eye). We've established CVVDP is relevant to the last point, so what additional criteria must we meet to use an implementation?</p>
<p>The Python implementation of CVVDP is compelling research-grade software, and a <a href="https://github.com/Line-fr/Vship">fully GPU-accelerated implementation</a> exists for video. While performant GPU acceleration is compelling for benchmarking videos, images have different needs:</p>
<ul>
<li>GPU initialization time causes slowdowns</li>
<li>Threading isn't important, because each encode/metric worker gets its own thread in the benchmark script</li>
<li>Batch processing on the GPU fixes the first issue, but requires re-architecting parts of our benchmark script for one metric</li>
</ul>
<p>So, fcvvdp should be able to slot into existing workflows as easily as SSIMULACRA2 or Butteraugli might relative to a legacy image benchmarking suite.</p>
<h2 id="implementation">Implementation</h2>
<p>fcvvdp is based on the GPU-accelerated implementation mentioned earlier, and is written in C. It is, predictably, strongest when it comes to images. The reference implementation takes (on average) 1.69 seconds and 928 MB of RAM to score one 576x576 pairwise image comparison. fcvvdp takes (on average) 85.5ms, and uses 61.5 MB of RAM. Scores are within a reasonable margin of perceptual error.</p>
<p>On a 360p video, fcvvdp is ~18% faster in terms of wall clock time. The benefits described above generalize in terms of user time and RAM usage, but wall clock time isn't much better on videos due to the fact that fcvvdp doesn't feature any sort of threading. This is the implementation's biggest limitation; while it is still faster than the reference implementation (which does feature threading) by a bit, threading would allow the relative improvement we see with images to generalize to video.</p>
<p>If you're interested in learning about how fcvvdp works, see our <a href="https://github.com/halidecx/fcvvdp/blob/main/doc/cvvdp.md">implementation docs</a>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Our code is public under the <a href="https://github.com/halidecx/fcvvdp?tab=Apache-2.0-1-ov-file#readme">Apache 2.0 license</a>. We are always proud of our capability to give back to the FOSS ecosystem when we can. While Iris is a closed source product, we hope to use Iris's impact and utility as a means of subsidizing work on open source when it helps support our mission. In this case, fcvvdp was the perfect excuse to do something great for Halide Compression while giving something valuable back to the field. We hope you enjoy fcvvdp!</p>
<div class="call-to-action">
  <a
    href="mailto:mail@halide.cx"
    class="cta-button"
  >
    Email Us
  </a>
</div>

  </div>
</article>

      </div>
      <div class="foot">
        &copy; 2025 Halide Compression LLC. All Rights Reserved. | <a href="https://halide.cx/privacy/">Privacy Policy</a>
      </div>
    </main>

    <script src="/js/mobile_menu.js"></script>
  </body>
</html>
